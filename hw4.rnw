\documentclass[11pt]{article}
\usepackage{fullpage,graphicx,float,amsmath,enumitem,hyperref}
\setlist{parsep=5.5pt}
\setlength{\parindent}{0pt}

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{Time Series HW 4}
\chead{October 3, 2016}
\rhead{Andrea Mack and Kenny Flagg}
\setlength{\headheight}{18pt}
\setlength{\headsep}{2pt}

\title{Time Series HW 4}
\author{Andrea Mack and Kenny Flagg}
\date{October 3, 2016}

\begin{document}
\maketitle

<<setup, echo = FALSE, message = FALSE, cache = FALSE>>=
require(knitr)
opts_chunk$set(echo = FALSE, comment = NA, fig.align = 'center',
               fig.width = 6.5, fig.height = 3, fig.pos = 'H',
               size = 'footnotesize', dev = 'pdf',
               dev.args = list(pointsize = 11))
knit_theme$set('print')

require(xtable)
options(xtable.table.placement = 'H', width = 80, show.signif.stars = FALSE)
@

{\it Due on Wednesday, Sept 28 at noon at my office.}

{\it You can work alone or in groups of up to three. No bonus. If you are turning in separate assignments, you must use a different site (discussed below).}

{\it We will now work with modeling monthly average C0$_2$ concentrations. The next bit of code works with the MLO (Mauna Loa) site's results.}

{\it For Mauna Loa, my data set looks like following and I subset it to only pertain to results after 1977 where there were no missing values. You can choose to keep years with missing values or cut those years from your analysis somewhat like I did.}

<<zero1, warning = FALSE>>=
MLO_flask <- read.csv('https://dl.dropboxusercontent.com/u/77307195/MLO_flask.csv', header = TRUE)
table(MLO_flask$year) # Great way to see how many observations you have per year
MLO_flaskR <- subset(MLO_flask, year > 1976)
MLOts <- ts(MLO_flaskR$value, start = c(1977, 1), freq = 12)
# Only use this if any missing values coded as NAs or no NAs in vector,
#otherwise you might need to avoid ts()

plot(MLOts)
@

{\it In this homework, your group will choose a different site and download the data set. There are 96 different locations to choose from at \url{http://www.esrl.noaa.gov/gmd/dv/data/index.php?parameter_name=Carbon%2BDioxide&frequency=Monthly%2BAverages}. Click the trash can with a green arrow to access a text file that contains the data set. I found it easiest to just copy the rows with data and headers into Excel and use ``Data -> Text to columns'' to create a more useful csv file. But the conversion details are up to you. Make sure your site has records for at least 6 years.}

{\it Report all R code either inline or in an appendix.}

\begin{enumerate}

\item%1
{\it Provide a reason for your choice of location. Report any missing observations and the range of years where you are modeling.}

Kenny and I chose to use the High Altitude Global Climate Observation Center, Mexico (MEX) dataset because we thought the High Altitude aspect may show interesting features of $CO_{2}$ concentrations not available in other datasets.

The information page on these data indicates measured responses are on the $X2007$ CO2 mole fraction scale. The excerpt from the information page gives insightful information about CO2 and the data:

``Carbon dioxide (CO2) in ambient and standard air samples is
detected using a non-dispersive infrared (NDIR) analyzer.
The measurement of CO2 in air is made relative to standards 
whose CO2 mole fraction is determined with high precision and 
accuracy. Because detector response is non-linear in the range
of atmospheric levels, ambient samples are bracketed during 
analysis by a set of reference standards used to calibrate 
detector response. Measurements are reported in units of 
micromol/mol ($10^{-6}$ mol CO2 per mol of dry air or parts per 
million (ppm)). Measurements are directly traceable to the 
WMO CO2 mole fraction scale.

Uncertainty in the measurements of CO2 from discrete samples 
has not yet been fully evaluated.  Key components of it are our
ability to propagate the WMO $XCO2$ scale to working standards, 
the repeatability of the analyzers used for sample measurement, 
and agreement between pairs of samples collected simultaneously.
Zhao and Tans (2006) determined that the internal consistency
of working standards is +/- 0.02 ppm (68\% confidence interval).
The typical repeatability of the analyzers, based on repeated 
measurements of natural air from a cylinder, is +/- 0.03 ppm.
Average pair agreement across the entire sampling network is
+/- 0.1 ppm.

The Pacific Ocean Cruise (POC, travelling between the US west coast
and New Zealand or Australia) data have been merged and grouped into 
5 degree latitude bins.  For the South China Sea cruises (SCS) the 
data are grouped in 3 degree latitude bins.

Sampling intervals are approximately weekly for the fixed sites
and average one sample every 3 weeks per latitude zone for POC and
about one sample every week per latitude for SCS.

Historically, samples have been collected using two general methods:
flushing and then pressurizing glass flasks with a pump, or opening a
stopcock on an evacuated glass flask; since 28 April 2003, only the
former method is used.  During each sampling event, a pair of flasks 
is filled."

<<prob1, include = FALSE>>=
require(car)
require(xtable)

x <- read.csv("mex.csv", as.is = TRUE)
colnames(x) <- c("year", "month", "value")
tail(x)#years spanning 2009-2016
@

\item%2
{\it Make a nice looking time series plot of the CO$_2$ concentrations.}

<<prob2, fig.height = 4, fig.width = 6, fig.align = 'center'>>=
ts_x <- ts(x)
plot.ts(ts_x[,3], xlab = "Time Series Index", ylab = "[CO2] Value")
@

\item%3
{\it Fit a linear trend plus seasonal means model to the data. Report and discuss the four panel residual diagnostics. Also make a plot of residuals vs time and discuss any potential missed pattern versus time.}

{\bf Residuals vs. Fitted}: The residuals vs. fitted plot shows a slight inverse quadratic trend, less variation in the residuals for extreme fitted CO2 concentrations, and a few outliers.

{\bf Normal QQ}: The standardized residuals fall on the Normal QQ line almost perfectly, making normality of the residuals a reasonable assumption.

{\bf Scale-Location}:

{\bf Residuals vs. Leverage}:

{\bf Residuals vs. Time}: There is slightly more variation in the the residuals associated with years 2012 and 2015.


<<prob3, fig.height = 4, fig.width = 6, fig.align = 'center'>>=
lm_x <- lm(value ~ year + as.factor(month), data = x)
par(mfrow = c(2,2))
plot(lm_x)

#Does he want fractional year?
@

<<prob3x, fig.height = 4, fig.width = 6, fig.align = 'center'>>=
#create fractional year variable
par(mfrow=c(1,1))

plot(lm_x$residuals ~ x$year, xlab = "Year", ylab = "Residuals")
@

\item%4
{\it Provide tests for the linear and seasonal means components, conditional on each other. Report those results in two sentences including all details.}

<<prob4, results = 'asis'>>=
#Make sure this means type II SS.
aov_x <- Anova(lm_x, type = "II")
#str(aov_x)

cat("$H_{o}: \\beta_{year} = 0$", "$H_{A}: \\beta_{year} \\neq 0$", "\n", "An F statistic of", aov_x$`F value`[1], "compared to an F distribution on", aov_x$Df[1], "and", aov_x$Df[3], "degrees of freedom let to a pvalue of", aov_x$`Pr(>F)`[1], "which provides strong evidence that after accounting for month, year is linearly associated with mean CO2 measurement.")

cat("$H_{o}: all \\beta_{month_{i}} = 0$", "$H_{A}:$", "at least 1", "$\\beta_{month_{i}} \\neq 0$", "\n", "An F statistic of", aov_x$`F value`[2], "compared to an F distribution on", aov_x$Df[2], "and", aov_x$Df[3], "degrees of freedom let to a pvalue of", aov_x$`Pr(>F)`[2], "which provides strong evidence that after accounting for linear yearly trends, month is associated with mean CO2 measurement.")



@

\item%5
{\it For your model, plot the original time series and the model fitted values, both versus time on the same plot. You might consider two line types or colors for the two lines. The easiest way to obtain fitted values in R is using \texttt{fitted(modelname)}. Discuss how it appears your model does or does not describe the responses using this plot.}

The dashed line is the original time series plot, and the fitted values are the solid line. The model almost perfectly describes the obseved CO2 concentrations because all the points lie almost exactly on the time series line.

<<prob5, fig.height = 4, fig.width = 6, fig.align = 'center'>>=
# I think it's visually misleading to compare points to lines.
# I made a solid line for the model so we can see the obvious seasonal
# variation around the linear trend. It does fit the data astoundingly well.
par(mfrow = c(1,1))
plot.ts(ts_x[,3], xlab = "Time Series Index", ylab = "[CO2] Value", lty = 2)
lines(lm_x$fitted.values, lty = 1)
@

\item%6
{\it Document your R version}

<<six1, echo = TRUE>>=
getRversion()
@

\end{enumerate}

\pagebreak
\section*{Reference}
Dlugokencky, E.J., P.M. Lang, J.W. Mund, A.M. Crotwell, 
   M.J. Crotwell, and K.W. Thoning (2016), Atmospheric Carbon Dioxide
   Dry Air Mole Fractions from the NOAA ESRL Carbon Cycle
   Cooperative Global Air Sampling Network, 1968-2015, Version: 2016-08-30,
   Path: \url{ftp://aftp.cmdl.noaa.gov/data/trace_gases/co2/flask/surface/}.

\appendix
\section*{R Code}

<<zero1, eval = FALSE>>=
@

\begin{enumerate}

\item%1
<<prob1, eval = FALSE, echo = TRUE>>=
@

\item%2
<<prob2, eval = FALSE, echo = TRUE>>=
@

\item%3
<<prob3, eval = FALSE, echo = TRUE>>=
@

\item%4
<<prob4, eval = FALSE, echo = TRUE>>=
@

\item%5
<<prob5, eval = FALSE, echo = TRUE>>=
@

\item%6
<<six1, eval = FALSE, echo = TRUE>>=
@

\end{enumerate}

\end{document}
